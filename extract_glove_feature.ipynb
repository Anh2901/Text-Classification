{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "# import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing#, decomposition, model_selection, metrics, pipeline\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106445, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26610, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "# sample = pd.read_csv('../input/sample_submission.csv')\n",
    "print(train.shape)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(3018,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e361c1faaa47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mrm_idx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   3116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 3118\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   3119\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (3018,)"
     ]
    }
   ],
   "source": [
    "# delete document with empty content\n",
    "rm_idx = []\n",
    "for i in range(len(test)):\n",
    "    if len(test.Text[i]) <= 20:\n",
    "        print(test.Text[i,])\n",
    "        rm_idx.append(i)\n",
    "\n",
    "# train = train.iloc[train.idx,]\n",
    "# print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4235, 4238, 4265, 8749, 8756, 8818, 18393, 18427, 19020, 25067, 27378, 27768, 31485, 31660, 31671, 31738, 40951, 41030, 41129, 41136, 41152, 41171, 41275, 41586, 42016, 45758, 45759, 45760, 45761, 50687, 51670, 51710, 52231, 52347, 52943, 66800, 70787, 78766, 92399, 92637, 94982, 97814, 98045, 101651, 101850, 101862, 102065, 102117, 102203]\n"
     ]
    }
   ],
   "source": [
    "print(rm_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106396, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = train.drop(train.index[rm_idx])\n",
    "# train.reset_index(drop=True, inplace=True)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1917494it [02:21, 13571.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917494 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe vectors in a dictionary:\n",
    "embeddings_index = {}\n",
    "f = open('D:/Master of Data Science/18S2-FIT5149 - Applied Data Analysis/Assignment/glove.42B.300d.txt', encoding=\"utf8\")\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import WordNet Lemmatizer from nltk \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "wordnet_lemmatizer = WordNetLemmatizer() \n",
    "lines_with_lemmas=[] #stop words contain the set of stop words \n",
    "for line in lines: \n",
    "temp_line=[] \n",
    "for word in lines: \n",
    "    temp_line.append (wordnet_lemmatizer.lemmatize(word)) \n",
    "    string=’ ‘ \n",
    "    lines_with_lemmas.append(string.join(temp_line)) \n",
    "    lines=lines_with_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates a scaled vector for an entire document\n",
    "def doc2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words) # tokenize the doc\n",
    "    words = [w for w in words if not w in stop_words] # remove stop words\n",
    "    words = [w for w in words if w.isalpha()] # remove numbers\n",
    "\n",
    "    # create an array excluding stopwords and numbers\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "\n",
    "    # for error document, convert into a 300d vector of 0\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "        \n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 106445/106445 [03:14<00:00, 548.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 26610/26610 [00:50<00:00, 524.76it/s]\n"
     ]
    }
   ],
   "source": [
    "xtrain = train.Text.values\n",
    "ytrain = train.label\n",
    "xtest = test.Text.values\n",
    "\n",
    "# create sentence vectors using the above function for training and validation set\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
    "xtest_glove = [sent2vec(x) for x in tqdm(xtest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_colname = []\n",
    "test_colname = []\n",
    "for i in range(300):\n",
    "    name = \"v\" + str(i)\n",
    "    train_colname.append(name)\n",
    "    test_colname.append(name)\n",
    "# print(train_colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_output = pd.DataFrame.from_records(xtrain_glove)\n",
    "test_output = pd.DataFrame.from_records(xtest_glove)\n",
    "\n",
    "train_output.columns = train_colname\n",
    "test_output.columns = test_colname\n",
    "\n",
    "# train_output['id'] = train.ID\n",
    "train_output['label'] = ytrain\n",
    "\n",
    "# test_output['id'] = test.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v0', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9',\n",
       "       ...\n",
       "       'v291', 'v292', 'v293', 'v294', 'v295', 'v296', 'v297', 'v298', 'v299',\n",
       "       'label'],\n",
       "      dtype='object', length=301)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106445, 301)\n",
      "(26610, 300)\n"
     ]
    }
   ],
   "source": [
    "# train_output = train_output[new_traincol]\n",
    "# test_output = test_output[new_testcol]\n",
    "print(train_output.shape)\n",
    "print(test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_output.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v0        0\n",
       "v1        0\n",
       "v2        0\n",
       "v3        0\n",
       "v4        0\n",
       "v5        0\n",
       "v6        0\n",
       "v7        0\n",
       "v8        0\n",
       "v9        0\n",
       "v10       0\n",
       "v11       0\n",
       "v12       0\n",
       "v13       0\n",
       "v14       0\n",
       "v15       0\n",
       "v16       0\n",
       "v17       0\n",
       "v18       0\n",
       "v19       0\n",
       "v20       0\n",
       "v21       0\n",
       "v22       0\n",
       "v23       0\n",
       "v24       0\n",
       "v25       0\n",
       "v26       0\n",
       "v27       0\n",
       "v28       0\n",
       "v29       0\n",
       "         ..\n",
       "v271      0\n",
       "v272      0\n",
       "v273      0\n",
       "v274      0\n",
       "v275      0\n",
       "v276      0\n",
       "v277      0\n",
       "v278      0\n",
       "v279      0\n",
       "v280      0\n",
       "v281      0\n",
       "v282      0\n",
       "v283      0\n",
       "v284      0\n",
       "v285      0\n",
       "v286      0\n",
       "v287      0\n",
       "v288      0\n",
       "v289      0\n",
       "v290      0\n",
       "v291      0\n",
       "v292      0\n",
       "v293      0\n",
       "v294      0\n",
       "v295      0\n",
       "v296      0\n",
       "v297      0\n",
       "v298      0\n",
       "v299      0\n",
       "label    C1\n",
       "Name: 4235, Length: 301, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output.iloc[4235,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output.to_csv('./train_glove_final.csv',index=False)\n",
    "test_output.to_csv('./test_glove_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          C1\n",
       "1          C1\n",
       "2          C1\n",
       "3          C1\n",
       "4          C1\n",
       "5          C1\n",
       "6          C1\n",
       "7          C1\n",
       "8          C1\n",
       "9          C1\n",
       "10         C1\n",
       "11         C1\n",
       "12         C1\n",
       "13         C1\n",
       "14         C1\n",
       "15         C1\n",
       "16         C1\n",
       "17         C1\n",
       "18         C1\n",
       "19         C1\n",
       "20         C1\n",
       "21         C1\n",
       "22         C1\n",
       "23         C1\n",
       "24         C1\n",
       "25         C1\n",
       "26         C1\n",
       "27         C1\n",
       "28         C1\n",
       "29         C1\n",
       "         ... \n",
       "106366    C23\n",
       "106367    C23\n",
       "106368    C23\n",
       "106369    C23\n",
       "106370    C23\n",
       "106371    C23\n",
       "106372    C23\n",
       "106373    C23\n",
       "106374    C23\n",
       "106375    C23\n",
       "106376    C23\n",
       "106377    C23\n",
       "106378    C23\n",
       "106379    C23\n",
       "106380    C23\n",
       "106381    C23\n",
       "106382    C23\n",
       "106383    C23\n",
       "106384    C23\n",
       "106385    C23\n",
       "106386    C23\n",
       "106387    C23\n",
       "106388    C23\n",
       "106389    C23\n",
       "106390    C23\n",
       "106391    C23\n",
       "106392    C23\n",
       "106393    C23\n",
       "106394    C23\n",
       "106395    C23\n",
       "Name: label, Length: 106396, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
